import pandas as pd
import requests
from datetime import timedelta, date
import pickle
import numpy as np

pd.set_option('display.max_rows',200)

start = date(2018, 1, 1)
end = date(2019, 1, 1)

df = pd.DataFrame()

for sdate in range((end - start).days):
    fdate = (start + timedelta(sdate)).strftime('%y%m%d')
    url = "http://web.mta.info/developers/data/nyct/turnstile/turnstile_" + fdate + ".txt"
    try:
        data = pd.read_csv(url)
        data['file'] = fdate
        df = df.append(data)
    except:
        pass

df['date'] = pd.to_datetime(df.DATE)

df['turnid'] = df['STATION'] + '/' + df['SCP'] + '/' + df['C/A']

df = df.sort_values(['STATION','turnid','TIME'])

df = df.rename(columns={ df.columns[10]: "EXITS" })

# Remove readings at unusual times (that don't land on an even hour)
df = df[df.TIME.str.contains(':00:00', regex=False)]

pickle.dump(df, open('turnstiledata','wb'))


df = pickle.load(open('turnstiledata','rb'))

# # Check which turnstiles have the expected 42 audits
# audit_counts = df.groupby(['turnid','date','TIME']).sum().groupby(['turnid']).count()
# bad_turnids = audit_counts[audit_counts['ENTRIES']!=42].reset_index().turnid
# len(bad_turnids)
# good_turnids = audit_counts[audit_counts['ENTRIES']==42].reset_index().turnid
# len(good_turnids)
# pd.DataFrame(bad_turnids)
# len(df)
# irregular = df.merge(pd.DataFrame(bad_turnids),on='turnid')
# irregular.groupby(['STATION','turnid','date','TIME']).sum()

# Sum up for the different DESC, for each turnstile/timeblock

# df[df.STATION.str.contains('TIMES SQ')].sort_values(['turnid','date','TIME'])
df = df.groupby(['STATION','turnid','date','TIME'], as_index=False).sum()

df['dayofweek'] = df.date.dt.day_name()
df['daytype'] = np.where(df['dayofweek'].isin(['Sunday','Saturday']), 'Weekend', 'Weekday')


# Create the net entries as differene in this row from following row entries
df['entries'] = df.ENTRIES.shift(-1) - df.ENTRIES
df['exits'] = df.EXITS.shift(-1) - df.EXITS
df['passages'] = df.entries + df.exits

# Delete last row for each turnstile, for which we can't calculate the net # entries
df = df.groupby(['turnid'], as_index=False).apply(lambda x: x.iloc[:-1])
#df[df.STATION.str.contains('LEXINGTON')][df.dayofweek.str.contains('Sunday')]
# Sum up turnstiles into stations
df = df.groupby(['STATION','date','daytype','TIME'], as_index=False).sum()

# Eliminate negatives at least
df = df[df.entries>0]
df = df[df.exits>0]

pickle.dump(df, open('turnstiledata2','wb'))


df = pickle.load(open('turnstiledata2','rb'))

df = df.groupby(['STATION','daytype','TIME']).agg(['median','count'])

df.columns = df.columns.droplevel(1)

df.columns = ['ENTRIES','ENTRIES_c','EXITS','EXITS_c','entries','entries_c','exits','exits_c','passages','passages_c']

df = df[df.passages_c >=3]

df[['entries','exits','passages']].sort_values(['entries'],ascending=False)
